---
title: "Project"
output: html_document
date: "2024-07-23"
---

## Project
``` {r}
library(tidyverse)
library(dplyr)
library(forcats)
library(ggplot2)
library(rpart)
library(caret)
library(rpart.plot)
library(C50)
library(Metrics)
library(e1071)
library(glmnet)

options(scipen = 999)  

setwd("/Users/19noa/Masters_Program/ADS502/Project")
recruitment <- read.csv("recruitment_data.csv", header = TRUE, sep=',')
head(recruitment,10)

recruitment<- recruitment %>%
  mutate(Gender = as.factor(Gender),
         EducationLevel = as.factor(EducationLevel),
         RecruitmentStrategy = as.factor(RecruitmentStrategy),
         HiringDecision = as.factor(HiringDecision),
         Gender_name = as.factor(ifelse(Gender == 0, "Male", "Female")),
         Hiring_name = as.factor(ifelse(HiringDecision == 0, "Not Hired", "Hired")),
         Recruitment_name = fct_collapse(RecruitmentStrategy,
                                         Aggressive = 1,
                                         Moderate = 2,
                                         Conservative = 3),
         Education_name = fct_collapse(EducationLevel,
                                       Bachelor_1 = 1,
                                       Bachelor_2 = 2,
                                       Masters = 3,
                                       PhD = 4))
head(recruitment,10)

sapply(recruitment, function(x) sum(is.na(x))) #count total missing values in each column of data frame
```

## Project
``` {r}
summary(recruitment)

dim(recruitment)
```
#Project
```{r}
ggplot(data = recruitment) +
geom_bar(aes(x = Recruitment_name, fill = Hiring_name)) +
xlab("Recruitment Type") +
guides(fill = guide_legend(title = "Hiring Decision"))
```
##Project
```{r}

ggplot(data = recruitment) +
geom_bar(aes(x = Gender_name, fill = Hiring_name)) +
xlab("Sex of Applicant") +
guides(fill = guide_legend(title = "Hiring Decision"))

```
## Project
```{r}

ggplot(data = recruitment) +
geom_bar(aes(x = Education_name, fill = Hiring_name)) +
xlab("Education Level") +
guides(fill = guide_legend(title = "Hiring Decision"))

```
##Project
```{r}

hiring_point<- function(x, y){
ggplot(data = recruitment) +
geom_point(aes(x = .data[[x]], y = .data[[y]], color = Hiring_name))
}

hiring_point("SkillScore", "PersonalityScore") +
guides(color = guide_legend(title = "Hiring Decision"))

```

##Project
```{r}

hiring_point("SkillScore", "InterviewScore") +
guides(color = guide_legend(title = "Hiring Decision"))

```

##Project
```{r}

ggplot(data = recruitment) +
geom_point(aes(x = SkillScore, y = InterviewScore, color = Gender_name))+
facet_grid(~Hiring_name) +
guides(color = guide_legend(title = "Sex of Applicant"))

```

```{r}

ggplot(data = recruitment) +
geom_point(aes(x = SkillScore, y = PersonalityScore, color = Gender_name)) +
facet_grid(~Hiring_name) +
guides(color = guide_legend(title = "Sex of Applicant"))
```
```{r}
#install.packages("ggcorrplot")
#if (!require(devtools)) install.packages("devtools") 
#devtools::install_github("kassambara/ggcorrplot")
library(ggcorrplot)
library(ggplot2)
corr<- cor(recruitment[,c(1, 4, 5, 6, 7, 8, 9)])

ggcorrplot(corr)
```

```{r}
library(caret)
set.seed(720) 

trainingRows <- createDataPartition(recruitment$Hiring_name, p = .75, list = FALSE)
recruit_train <- recruitment[trainingRows, ]
recruit_test <- recruitment[-trainingRows, ]

logreg_train <- glm(formula = HiringDecision ~ Age + Gender + EducationLevel + ExperienceYears + PreviousCompanies + DistanceFromCompany +InterviewScore + SkillScore + PersonalityScore +
                      RecruitmentStrategy, data = recruit_train, family = binomial)
summary(logreg_train)
```

```{r}

logreg_test <- glm(formula = HiringDecision ~ Age + Gender + EducationLevel + ExperienceYears + PreviousCompanies + DistanceFromCompany +InterviewScore + SkillScore + PersonalityScore +
                      RecruitmentStrategy, data = recruit_test, family = binomial)
summary(logreg_test)

##Education Level, Age, Gender, Previous Companies, and Distance from company will be removed since they are not statistically significant (p > .05)and this has been validated with the testing data set. 

```
```{r}

logreg_train <- glm(formula = HiringDecision ~ ExperienceYears +InterviewScore + SkillScore + PersonalityScore + RecruitmentStrategy, data = recruit_train, family = binomial)
summary(logreg_train)

```

```{r}

predicted_train <- predict(logreg_train, newdata = recruit_train, type = "response")

predicted_classes <- ifelse(predicted_train > 0.5, 1, 0)

t1 <- table(recruit_train$HiringDecision, predicted_classes)
row.names(t1) <- c("Actual: 0", "Actual: 1")
colnames(t1) <- c("Predicted: 0", "Predicted: 1")
t1 <- addmargins(A = t1, FUN = list(Total = sum), quiet = TRUE) 
t1

```

```{r}

TN <- t1[1,1]
#print(paste("TN:", TN))
TP <- t1[2,2]
#print(paste("TP:", TP))
FN <- t1[2,1]
#print(paste("FN:", FN))
FP <- t1[1,2]
#print(paste("FP:", FP))
GT <- TN + TP + FN + FP

accuracy <- (TP + TN) / GT
error_rate <- 1 - accuracy
sensitivity <- TP / (TP + FN)
specificity <- TN / (TN + FP)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1 <- 2 * (precision * recall) / (precision + recall)
f2 <- (5 * precision * recall) / ((4 * precision) + recall)
f05 <- ((1.25 * precision * recall) / ((0.25 * precision) + recall))

model_evaluation_table <- data.frame(
  Evaluation_Measure = c("Accuracy", "Error Rate", "Sensitivity", "Specificity", "Precision", "F1 Score", "F2 Score", "F0.5 Score"),
  Logistic_Regression_Training_Model = c(accuracy, error_rate, sensitivity, specificity, precision, f1, f2, f05)
)

model_evaluation_table
```

```{r}

logreg_test <- glm(formula = HiringDecision ~ ExperienceYears + InterviewScore + SkillScore + PersonalityScore + RecruitmentStrategy, data = recruit_test, family = binomial)
summary(logreg_test)

```

```{r}

predicted_test <- predict(logreg_test, newdata = recruit_test, type = "response")

predicted_test_classes <- ifelse(predicted_test > 0.5, 1, 0)

t2 <- table(recruit_test$HiringDecision, predicted_test_classes)
row.names(t2) <- c("Actual: 0", "Actual: 1")
colnames(t2) <- c("Predicted: 0", "Predicted: 1")
t2 <- addmargins(A = t2, FUN = list(Total = sum), quiet = TRUE) 
t2

```

```{r}

TN1 <- t2[1,1]
#print(paste("TN:", TN1))
TP1 <- t2[2,2]
#print(paste("TP:", TP1))
FN1 <- t2[2,1]
#print(paste("FN:", FN1))
FP1 <- t2[1,2]
#print(paste("FP:", FP1))
GT1 <- TN1 + TP1 + FN1 + FP1

accuracy1 <- (TP1 + TN1) / GT1
error_rate1 <- 1 - accuracy1
sensitivity1 <- TP1 / (TP1 + FN1)
specificity1 <- TN1 / (TN1 + FP1)
precision1 <- TP1 / (TP1 + FP1)
recall1 <- TP1 / (TP1 + FN1)
f1_1 <- 2 * (precision1 * recall1) / (precision1 + recall1)
f2_1 <- (5 * precision1 * recall1) / ((4 * precision1) + recall1)
f05_1 <- ((1.25 * precision1 * recall1) / ((0.25 * precision1) + recall1))

model_evaluation_table <- data.frame(
  Evaluation_Measure = c("Accuracy", "Error Rate", "Sensitivity", "Specificity", "Precision", "F1 Score", "F2 Score", "F0.5 Score"),
  Logistic_Regression_Training_Model = c(accuracy, error_rate, sensitivity, specificity, precision, f1, f2, f05),
  Logistic_Regression_Testing_Model = c(accuracy1, error_rate1, sensitivity1, specificity1, precision1, f1_1, f2_1, f05_1)
)

model_evaluation_table
```

```{r}

nb01 <- naiveBayes(formula = HiringDecision ~ ExperienceYears + InterviewScore + SkillScore + PersonalityScore + RecruitmentStrategy, data = recruit_train)
ypred <- predict(object = nb01, newdata = recruit_train)
nb01
```

```{r}

t3 <- table(recruit_train$HiringDecision, ypred)
row.names(t3) <- c("Actual: 0", "Actual: 1")
colnames(t3) <- c("Predicted: 0", "Predicted: 1")
t3 <- addmargins(A = t3, FUN = list(Total = sum), quiet = TRUE) 
t3
```

```{r}

TN2 <- t3[1,1]
TP2 <- t3[2,2]
FN2 <- t3[2,1]
FP2 <- t3[1,2]
GT2 <- TN2 + TP2 + FN2 + FP2

accuracy2 <- (TP2 + TN2) / GT2
error_rate2 <- 1 - accuracy2
sensitivity2 <- TP2 / (TP2 + FN2)
specificity2 <- TN2 / (TN2 + FP2)
precision2 <- TP2 / (TP2 + FP2)
recall2 <- TP2 / (TP2 + FN2)
f1_2 <- 2 * (precision2 * recall2) / (precision2 + recall2)
f2_2 <- (5 * precision2 * recall2) / ((4 * precision2) + recall2)
f05_2 <- ((1.25 * precision2 * recall2) / ((0.25 * precision2) + recall2))

model_evaluation_table <- data.frame(
  Evaluation_Measure = c("Accuracy", "Error Rate", "Sensitivity", "Specificity", "Precision", "F1 Score", "F2 Score", "F0.5 Score"),
  Logistic_Regression_Training_Model = c(accuracy, error_rate, sensitivity, specificity, precision, f1, f2, f05),
  Logistic_Regression_Testing_Model = c(accuracy1, error_rate1, sensitivity1, specificity1, precision1, f1_1, f2_1, f05_1),
  Naive_Bayes_Training_Model = c(accuracy2, error_rate2, sensitivity2, specificity2, precision2, f1_2, f2_2, f05_2)
)

model_evaluation_table
```

```{r}

nb01_test <- naiveBayes(formula = HiringDecision ~ ExperienceYears + InterviewScore + SkillScore + PersonalityScore + RecruitmentStrategy, data = recruit_test)
ypred_test <- predict(object = nb01_test, newdata = recruit_test)
nb01_test
```
```{r}

t4 <- table(recruit_test$HiringDecision, ypred_test)
row.names(t4) <- c("Actual: 0", "Actual: 1")
colnames(t4) <- c("Predicted: 0", "Predicted: 1")
t4 <- addmargins(A = t4, FUN = list(Total = sum), quiet = TRUE) 
t4
```

```{r}

TN3 <- t4[1,1]
TP3 <- t4[2,2]
FN3 <- t4[2,1]
FP3 <- t4[1,2]
GT3 <- TN3 + TP3 + FN3 + FP3

accuracy3 <- (TP3 + TN3) / GT3
error_rate3 <- 1 - accuracy3
sensitivity3 <- TP3 / (TP3 + FN3)
specificity3 <- TN3 / (TN3 + FP3)
precision3 <- TP3 / (TP3 + FP3)
recall3 <- TP3 / (TP3 + FN3)
f1_3 <- 2 * (precision3 * recall3) / (precision3 + recall3)
f2_3 <- (5 * precision3 * recall3) / ((4 * precision3) + recall3)
f05_3 <- ((1.25 * precision3 * recall3) / ((0.25 * precision3) + recall3))

model_evaluation_table <- data.frame(
  Evaluation_Measure = c("Accuracy", "Error Rate", "Sensitivity", "Specificity", "Precision", "F1 Score", "F2 Score", "F0.5 Score"),
  Logistic_Regression_Training_Model = c(accuracy, error_rate, sensitivity, specificity, precision, f1, f2, f05),
  Logistic_Regression_Testing_Model = c(accuracy1, error_rate1, sensitivity1, specificity1, precision1, f1_1, f2_1, f05_1),
  Naive_Bayes_Training_Model = c(accuracy2, error_rate2, sensitivity2, specificity2, precision2, f1_2, f2_2, f05_2),
  Naive_Bayes_Testing_Model = c(accuracy3, error_rate3, sensitivity3, specificity3, precision3, f1_3, f2_3, f05_3)
)

model_evaluation_table
```
```